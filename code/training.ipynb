{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAF level Food Outflow Prediction GNN Model 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GATConv, GCNConv\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "from model import GCN, GAT\n",
    "from utils import train, test\n",
    "\n",
    "\n",
    "node_df = pd.read_csv(\"data/faf_features.csv\")\n",
    "edges_df = pd.read_csv(\"data/FAF5_SCTG1.csv\")\n",
    "distance_matrix = pd.read_csv(\"data/FAF_distance_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FAF_Zone       PC1       PC2       PC3       PC4       PC5       PC6  \\\n",
      "0        11 -2.006389 -1.821179 -0.404133 -0.051127 -0.039310 -0.031745   \n",
      "1        12 -2.252152 -2.966382 -0.515396 -0.162503 -0.493764 -0.271856   \n",
      "2        19 -0.920872 -0.456392  0.187202  1.573729  2.261417  1.221892   \n",
      "3        20 -2.195409 -2.849311 -0.482327 -0.235577 -0.419569 -0.166418   \n",
      "4        41 -1.771784  3.844207 -0.414339 -1.369063 -0.507529 -0.092140   \n",
      "\n",
      "        PC7       PC8       PC9      PC10      PC11      PC12      PC13  \\\n",
      "0 -0.246841 -0.120840 -0.225222  0.184540 -0.209944  0.092995 -0.052166   \n",
      "1 -0.260259 -0.188177 -0.436677  0.285102 -0.211547 -0.020487 -0.225732   \n",
      "2  0.113730  0.256403  0.855411  0.019502 -0.085308  1.110365  0.740245   \n",
      "3 -0.278788 -0.171916  0.000443  0.156871 -0.079351 -0.046955  0.267000   \n",
      "4 -0.305219 -0.244953 -0.370453  0.173976 -0.438941 -0.218421 -0.102978   \n",
      "\n",
      "       PC14      PC15  \n",
      "0  0.176254  0.079381  \n",
      "1  0.111855 -0.045005  \n",
      "2  0.978474  0.417557  \n",
      "3 -0.068171 -0.044632  \n",
      "4  0.058036 -0.108993  \n"
     ]
    }
   ],
   "source": [
    "# PCA for feature reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "features_scaler = StandardScaler()\n",
    "node_df.iloc[:, 1:] = features_scaler.fit_transform(node_df.iloc[:, 1:])\n",
    "node_df.head()\n",
    "\n",
    "# Select the features to be reduced\n",
    "features = node_df.drop(columns=['FAF_Zone'])\n",
    "\n",
    "# Apply PCA for feature reduction\n",
    "pca = PCA(n_components=15)  # Adjust the number of components as needed\n",
    "reduced_features = pca.fit_transform(features)\n",
    "\n",
    "# Create a new DataFrame with the reduced features\n",
    "reduced_df = pd.DataFrame(reduced_features, columns=[f'PC{i+1}' for i in range(reduced_features.shape[1])])\n",
    "reduced_df = pd.concat([node_df['FAF_Zone'], reduced_df], axis=1)\n",
    "\n",
    "# Update node_df with the reduced features\n",
    "node_df = reduced_df\n",
    "\n",
    "# Verify the changes\n",
    "print(node_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dms_orig</th>\n",
       "      <th>dms_dest</th>\n",
       "      <th>tons_2017</th>\n",
       "      <th>dms_mode</th>\n",
       "      <th>dist_band</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>51.010231</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>385.622345</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>129</td>\n",
       "      <td>1.360447</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>131</td>\n",
       "      <td>12.489625</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>139</td>\n",
       "      <td>5.134423</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dms_orig  dms_dest   tons_2017  dms_mode  dist_band\n",
       "0        11        11   51.010231         1          1\n",
       "1        11        19  385.622345         1          2\n",
       "2        11       129    1.360447         1          3\n",
       "3        11       131   12.489625         1          2\n",
       "4        11       139    5.134423         1          2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter edges_df to only include the relevant columns\n",
    "edges_df = edges_df[['dms_orig', 'dms_dest', 'tons_2017', 'dms_mode', 'dist_band']]\n",
    "edges_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dms_orig</th>\n",
       "      <th>dms_dest</th>\n",
       "      <th>tons_2017</th>\n",
       "      <th>dms_mode</th>\n",
       "      <th>dist_band</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>51.010231</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>17.012234</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>385.622345</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>61</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dms_orig  dms_dest   tons_2017  dms_mode  dist_band\n",
       "0        11        11   51.010231         1          1\n",
       "1        11        12   17.012234         1          2\n",
       "2        11        19  385.622345         1          2\n",
       "3        11        20    0.000000         4          8\n",
       "4        11        61    0.000056         4          7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by origin and destination and sum the tons values\n",
    "# Get the most common mode and distance band\n",
    "edges_df = edges_df.groupby(['dms_orig', 'dms_dest']).agg({\n",
    "    'tons_2017': 'sum',  # Sum the tons values\n",
    "    'dms_mode': lambda x: x.mode()[0] if not x.empty else None,  # Get the most common mode\n",
    "    'dist_band': lambda x: x.mode()[0] if not x.empty else None  # Get the most common distance band\n",
    "}).reset_index()\n",
    "edges_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6680\n"
     ]
    }
   ],
   "source": [
    "print(len(edges_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add missing edges with default 0 values\n",
    "uniques = edges_df['dms_orig'].unique()\n",
    "for i in uniques:\n",
    "    for j in uniques:\n",
    "        # Check if the pair (i, j) exists in the dataframe\n",
    "        if not ((edges_df['dms_orig'] == i) & (edges_df['dms_dest'] == j)).any():\n",
    "            # If not, add a new row with tons_2017 = 0 (which will be set to small_value later)\n",
    "            # For mode and dist_band, use the most common values as defaults\n",
    "            default_mode = edges_df['dms_mode'].mode()[0]\n",
    "            default_dist_band = edges_df['dist_band'].mode()[0]\n",
    "\n",
    "            new_row = pd.DataFrame({\n",
    "                'dms_orig': [i],\n",
    "                'dms_dest': [j],\n",
    "                'tons_2017': [0],  # This will be adjusted to small_value in the next cell\n",
    "                'dms_mode': [0],\n",
    "                'dist_band': [0]\n",
    "            })\n",
    "\n",
    "            # Append the new row to the dataframe\n",
    "            edges_df = pd.concat([edges_df, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dms_orig  dms_dest   tons_2017  dms_mode  dist_band     distance\n",
      "0        11        11   51.010231         1          1     0.000000\n",
      "1        11        12   17.012234         1          2   330.684950\n",
      "2        11        19  385.622345         1          2    71.542974\n",
      "3        11        20    0.000000         4          8  5740.453730\n",
      "4        11        61    0.000056         4          7  2746.348341\n"
     ]
    }
   ],
   "source": [
    "# add distance between origin and destination to edges_df\n",
    "distances = []\n",
    "for i, row in edges_df.iterrows():\n",
    "\n",
    "    src = row['dms_orig']\n",
    "    dst = row['dms_dest']\n",
    "    # Convert to string with leading zeros, ensuring they're integers first\n",
    "    src_str = str(int(src))\n",
    "    dst_str = str(int(dst)).zfill(3)\n",
    "    distance_matrix['FAF_Zone'] = distance_matrix['FAF_Zone'].astype(str)\n",
    "    dist = distance_matrix.loc[distance_matrix['FAF_Zone'] == src_str, dst_str].values[0]\n",
    "    distances.append(dist)\n",
    "\n",
    "edges_df['distance'] = distances\n",
    "print(edges_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Edges dataframe with remapped indices:\n",
      "   dms_orig  dms_dest   tons_2017  dms_mode  dist_band     distance\n",
      "0         0         0   51.010231         1          1     0.000000\n",
      "1         0         1   17.012234         1          2   330.684950\n",
      "2         0         2  385.622345         1          2    71.542974\n",
      "3         0         3    0.000000         4          8  5740.453730\n",
      "4         0         8    0.000056         4          7  2746.348341\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping dictionary for FAF zones\n",
    "faf_zones = node_df['FAF_Zone'].unique()\n",
    "zone_to_idx = {zone: idx for idx, zone in enumerate(faf_zones)}\n",
    "idx_to_zone = {idx: zone for idx, zone in enumerate(faf_zones)}\n",
    "node_df['FAF_Zone'] = node_df['FAF_Zone'].map(zone_to_idx)\n",
    "\n",
    "# Remap the origin and destination in edges_df\n",
    "edges_df['dms_orig'] = edges_df['dms_orig'].map(zone_to_idx)\n",
    "edges_df['dms_dest'] = edges_df['dms_dest'].map(zone_to_idx)\n",
    "\n",
    "# Check the remapped data\n",
    "print(\"\\nEdges dataframe with remapped indices:\")\n",
    "print(edges_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dms_orig  dms_dest   tons_2017     distance  dms_mode_0  dms_mode_1  \\\n",
      "0         0         0   51.010231     0.000000           0           1   \n",
      "1         0         1   17.012234   330.684950           0           1   \n",
      "2         0         2  385.622345    71.542974           0           1   \n",
      "3         0         3    0.000000  5740.453730           0           0   \n",
      "4         0         8    0.000056  2746.348341           0           0   \n",
      "\n",
      "   dms_mode_2  dms_mode_4  dms_mode_5  dms_mode_7  dist_band_0  dist_band_1  \\\n",
      "0           0           0           0           0            0            1   \n",
      "1           0           0           0           0            0            0   \n",
      "2           0           0           0           0            0            0   \n",
      "3           0           1           0           0            0            0   \n",
      "4           0           1           0           0            0            0   \n",
      "\n",
      "   dist_band_2  dist_band_3  dist_band_4  dist_band_5  dist_band_6  \\\n",
      "0            0            0            0            0            0   \n",
      "1            1            0            0            0            0   \n",
      "2            1            0            0            0            0   \n",
      "3            0            0            0            0            0   \n",
      "4            0            0            0            0            0   \n",
      "\n",
      "   dist_band_7  dist_band_8  \n",
      "0            0            0  \n",
      "1            0            0  \n",
      "2            0            0  \n",
      "3            0            1  \n",
      "4            1            0  \n"
     ]
    }
   ],
   "source": [
    "#one hot encode the dms_mode and dist_band\n",
    "edges_df = pd.get_dummies(edges_df, columns=['dms_mode', 'dist_band'], dtype=int)\n",
    "print(edges_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the target columns\n",
    "edges_df['tons_2017'] = np.log1p(edges_df['tons_2017'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dms_orig  dms_dest  tons_2017  distance  dms_mode_0  dms_mode_1  \\\n",
      "0         0         0   3.951440 -1.311748           0           1   \n",
      "1         0         1   2.891051 -1.073709           0           1   \n",
      "2         0         2   5.957448 -1.260249           0           1   \n",
      "3         0         3   0.000000  2.820443           0           0   \n",
      "4         0         8   0.000056  0.665175           0           0   \n",
      "\n",
      "   dms_mode_2  dms_mode_4  dms_mode_5  dms_mode_7  dist_band_0  dist_band_1  \\\n",
      "0           0           0           0           0            0            1   \n",
      "1           0           0           0           0            0            0   \n",
      "2           0           0           0           0            0            0   \n",
      "3           0           1           0           0            0            0   \n",
      "4           0           1           0           0            0            0   \n",
      "\n",
      "   dist_band_2  dist_band_3  dist_band_4  dist_band_5  dist_band_6  \\\n",
      "0            0            0            0            0            0   \n",
      "1            1            0            0            0            0   \n",
      "2            1            0            0            0            0   \n",
      "3            0            0            0            0            0   \n",
      "4            0            0            0            0            0   \n",
      "\n",
      "   dist_band_7  dist_band_8  \n",
      "0            0            0  \n",
      "1            0            0  \n",
      "2            0            0  \n",
      "3            0            1  \n",
      "4            1            0  \n"
     ]
    }
   ],
   "source": [
    "edges_df['distance'] = features_scaler.fit_transform(edges_df.iloc[:, 3].values.reshape(-1, 1))\n",
    "\n",
    "print(edges_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Extract node features\n",
    "node_features = []\n",
    "for i, row in node_df.iterrows():\n",
    "    node_features.append(torch.tensor(row.iloc[1:].values, dtype=torch.float))\n",
    "node_features = torch.stack(node_features)\n",
    "# Extract edge information (source, target)\n",
    "edge_index = torch.tensor(edges_df[['dms_orig', 'dms_dest']].values.T, dtype=torch.long)\n",
    "\n",
    "# Extract edge target values (food flow)\n",
    "edge_y = torch.tensor(edges_df['tons_2017'].values, dtype=torch.float).view(-1, 1)\n",
    "\n",
    "# Extract additional edge features\n",
    "edge_attr = torch.tensor(edges_df.iloc[:, 3:].values, dtype=torch.float)  # Excluding source, target, food_flow\n",
    "\n",
    "# Create PyG Data object\n",
    "data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr, y=edge_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 13939 edges, Test data: 3485 edges\n",
      "Train shapes - edge_index: torch.Size([2, 13939]), y: torch.Size([13939, 1])\n",
      "Test shapes - edge_index: torch.Size([2, 3485]), y: torch.Size([3485, 1])\n",
      "Epoch 0, Loss: 0.6037652\n",
      "Test MSE: 0.5585471, R²: -0.1487805, Accuracy: 0.7420373, RMSE: 0.7473601\n",
      "Epoch 100, Loss: 0.2724480\n",
      "Test MSE: 0.2924808, R²: 0.3984460, Accuracy: 0.8748924, RMSE: 0.5408149\n",
      "Epoch 200, Loss: 0.2694708\n",
      "Test MSE: 0.2921169, R²: 0.3991943, Accuracy: 0.8766140, RMSE: 0.5404784\n",
      "Epoch 300, Loss: 0.2680950\n",
      "Test MSE: 0.2916277, R²: 0.4002005, Accuracy: 0.8769010, RMSE: 0.5400257\n",
      "Epoch 400, Loss: 0.2671180\n",
      "Test MSE: 0.2911862, R²: 0.4011086, Accuracy: 0.8771880, RMSE: 0.5396167\n",
      "Epoch 499, Loss: 0.2662142\n",
      "Test MSE: 0.2905937, R²: 0.4023273, Accuracy: 0.8748924, RMSE: 0.5390674\n"
     ]
    }
   ],
   "source": [
    "# Create train/test split properly\n",
    "num_edges = data.edge_index.shape[1]\n",
    "train_size = int(num_edges * 0.8)\n",
    "indices = torch.randperm(num_edges, generator=torch.Generator().manual_seed(42))\n",
    "train_indices = indices[:train_size]\n",
    "test_indices = indices[train_size:]\n",
    "\n",
    "train_data = Data(\n",
    "    x=data.x,\n",
    "    edge_index=data.edge_index[:, train_indices],\n",
    "    edge_attr=data.edge_attr[train_indices],\n",
    "    y=data.y[train_indices]\n",
    ")\n",
    "\n",
    "test_data = Data(\n",
    "    x=data.x,\n",
    "    edge_index=data.edge_index[:, test_indices],\n",
    "    edge_attr=data.edge_attr[test_indices],\n",
    "    y=data.y[test_indices]\n",
    ")\n",
    "\n",
    "# Debug info\n",
    "print(f\"Train data: {len(train_indices)} edges, Test data: {len(test_indices)} edges\")\n",
    "print(f\"Train shapes - edge_index: {train_data.edge_index.shape}, y: {train_data.y.shape}\")\n",
    "print(f\"Test shapes - edge_index: {test_data.edge_index.shape}, y: {test_data.y.shape}\")\n",
    "\n",
    "\n",
    "gcn_model = GCN(in_channels=data.x.shape[1], hidden_channels=64, edge_feature_dim=data.edge_attr.shape[1])\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "optimizer = torch.optim.SGD(gcn_model.parameters(), lr=0.01, momentum=0.9)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "epochs = 500\n",
    "# Train the model\n",
    "for epoch in range(epochs):  # Reduced epochs for faster debugging\n",
    "\n",
    "    loss_value = train(gcn_model, train_data, loss, optimizer)\n",
    "\n",
    "\n",
    "    if epoch % 100 == 0 or epoch == epochs-1:\n",
    "        print(f'Epoch {epoch}, Loss: {loss_value:.7f}')\n",
    "        mse, r2, accuracy = test(gcn_model, test_data)\n",
    "        rmse = np.sqrt(mse)\n",
    "        print(f\"Test MSE: {mse:.7f}, R²: {r2:.7f}, Accuracy: {accuracy:.7f}, RMSE: {rmse:.7f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.5820481\n",
      "Test MSE: 0.4983346, R²: -0.0249396, Accuracy: 0.7417504, RMSE: 0.7059282\n",
      "Epoch 100, Loss: 0.3631998\n",
      "Test MSE: 0.3784314, R²: 0.2216688, Accuracy: 0.8783357, RMSE: 0.6151678\n",
      "Epoch 200, Loss: 0.2958981\n",
      "Test MSE: 0.3126062, R²: 0.3570534, Accuracy: 0.8809182, RMSE: 0.5591120\n",
      "Epoch 300, Loss: 0.2785603\n",
      "Test MSE: 0.2958129, R²: 0.3915927, Accuracy: 0.8769010, RMSE: 0.5438869\n",
      "Epoch 400, Loss: 0.2752846\n",
      "Test MSE: 0.2936680, R²: 0.3960042, Accuracy: 0.8748924, RMSE: 0.5419115\n",
      "Epoch 499, Loss: 0.2737745\n",
      "Test MSE: 0.2931401, R²: 0.3970900, Accuracy: 0.8760402, RMSE: 0.5414241\n"
     ]
    }
   ],
   "source": [
    "gat_model = GAT(in_channels=data.x.shape[1], hidden_channels=64, edge_feature_dim=data.edge_attr.shape[1])\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "optimizer = torch.optim.SGD(gat_model.parameters(), lr=0.01, momentum=0.9)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "epochs = 500\n",
    "# Train the model\n",
    "for epoch in range(epochs):  # Reduced epochs for faster debugging\n",
    "    # Fix the train function call - it should return a tensor loss, not use the loss object\n",
    "    loss_value = train(gat_model, train_data, loss, optimizer)\n",
    "\n",
    "    # Print shapes periodically for debugging\n",
    "    if epoch % 100 == 0 or epoch == epochs-1:\n",
    "        print(f'Epoch {epoch}, Loss: {loss_value:.7f}')\n",
    "        mse, r2, accuracy = test(gat_model, test_data)\n",
    "        rmse = np.sqrt(mse)\n",
    "        print(f\"Test MSE: {mse:.7f}, R²: {r2:.7f}, Accuracy: {accuracy:.7f}, RMSE: {rmse:.7f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT model saved to saved_models/gat_model.pth\n",
      "GCN model saved to saved_models/gcn_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the GAT model\n",
    "torch.save(gat_model.state_dict(), 'models/gat_model.pth')\n",
    "print(\"GAT model saved to saved_models/gat_model.pth\")\n",
    "\n",
    "# Save the GCN model\n",
    "torch.save(gcn_model.state_dict(), 'models/gcn_model.pth')\n",
    "print(\"GCN model saved to saved_models/gcn_model.pth\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
